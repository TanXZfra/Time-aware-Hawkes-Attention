data_config:
  train_dir: data/data_stackoverflow/train.json
  valid_dir: data/data_stackoverflow/valid.json
  test_dir: data/data_stackoverflow/test.json
  data_format: json
  data_specs:
    num_event_types: 22
    pad_token_id: 22
    padding_side: right
    truncation_side: right
    padding_strategy: null
    truncation_strategy: null
    max_len: null
base_config:
  stage: train
  backend: torch
  dataset_id: stackoverflow
  runner_id: std_tpp
  model_id: HawkesTHP
  base_dir: ./checkpoints/
  specs:
    log_folder: ./checkpoints/34284_33216_250723-000331
    saved_model_dir: ./checkpoints/34284_33216_250723-000331\models\saved_model
    saved_log_dir: ./checkpoints/34284_33216_250723-000331\log
    output_config_dir: ./checkpoints/34284_33216_250723-000331\HawkesTHP_train_output.yaml
model_config:
  rnn_type: LSTM
  hidden_size: 64
  time_emb_size: 4
  num_layers: 2
  sharing_param_layer: false
  loss_integral_num_sample_per_step: 20
  dropout_rate: 0.1
  use_ln: true
  thinning:
    num_seq: 10
    num_sample: 1
    num_exp: 500
    look_ahead_time: 10
    patience_counter: 5
    over_sample_rate: 5
    num_samples_boundary: 5
    dtime_max: 5
    num_step_gen: 1
  num_event_types_pad: 23
  num_event_types: 22
  event_pad_index: 22
  model_id: HawkesTHP
  pretrained_model_dir: null
  gpu: -1
  model_specs: {}
  d_model: 32
  d_k: 32
  d_v: 32
  phi_width: 8
  phi_depth: 2
  rnn: true
  d_rnn: 32
trainer_config:
  seed: 2025
  gpu: -1
  batch_size: 64
  max_epoch: 500
  shuffle: false
  optimizer: adam
  learning_rate: 0.001
  valid_freq: 1
  use_tfb: false
  metrics:
  - acc
  - rmse
  l2_coef: 0.1
